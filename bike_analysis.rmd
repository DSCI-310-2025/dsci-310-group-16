---
title: "Predicting Bike Rental Demand Using Regression Analysis"
author: "Annmarie Thomson"
date: "2025-1-3"
output: github_document
---

```{r}
set.seed(2024)
library(vroom)
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(ucimlrepo)
library(leaps)
library(mltools)
library(ggpubr)
```

## Predicting Bike Rental Demand Using Regression Analysis

### Summary

In our project, we will attempt to build a regression model using best subset selection to analyze bike-sharing data to predict rental demand. We will examine factors like weather, time, and holidays to understand their influence on bike usage.

### Introduction

Bike-sharing systems are a growing compotonent of urban design (Winters, 2020), providing an eco-friendly, convenient, and healthy alternative to traditional transient or driving. Building understanding around the factors that drive bike-share demand can help urban designers improve bike services. The dataset we used to form our regression is the Bike Sharing Dataset (dataset ID: 275) from the UCI Machine Learning Repository, which you can find at <https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset>. It contains information on bike rentals, weather, and time-related features. Our research question: How do environmental and temporal factors affect bike-sharing demand?

### Methods and Results

Our dataset was loaded and cleaned by ensuring correct factorization and removing irrelevant columns

```{r read and clean data}
bike <- fetch_ucirepo(id = 275)
bike_data <- bike$data$original
bike_data <- bike_data %>%
  select(-instant, -dteday)
bike_data <- bike_data %>%
  mutate(weathersit = as.factor(weathersit))
bike_data <- bike_data %>%
  mutate(cnt = as.numeric(cnt))
write_csv(bike_data, "../dsci-310-group-16/data/bike_data.csv")
```

In our exploratory analysis, we looked to see how dependent variables affected bike rental usage. We also made a correlation matrix to explore how correlated our variables are. We found multicollinearity between atemp and temp, so moving forward we will use temp in our analysis. Finally, we found that the distribution of bike rental counts was heavily right skewed. Because we plan to use linear regression and we want to maintain the assumption of normality, moving forward we will be using a log transformation on the cnt variable.

```{}
```

```{r exploratory analysis}
summary(bike_data)
head(bike_data)
sum(is.na(bike_data))

total_rentals = ggplot(bike_data,aes(x = cnt))+
geom_histogram(binwidth = 10, fill = "blue",color = "black",alpha = 0.7)+
labs(title = "Histogram of the total bike rentals", x = "Total rentals")

cor(bike_data %>% select(temp, atemp, hum, windspeed, casual, registered, cnt))

temp_vs_rentals = ggplot(bike_data, aes(x = temp, y = cnt)) +
  geom_point(color = "blue", alpha = 0.5) +
  theme_minimal() +
  labs(title = "Temperature vs Bike Rentals", x = "Temperature", y = "Total Bike Rentals")


weather_vs_cnt = ggplot(bike_data, aes(x = factor(weathersit), y = cnt, fill = factor(weathersit))) +
  geom_bar(stat = "identity") +
  scale_x_discrete(labels=c("Clear/Partly Cloudy", "Mist and Cloudy", "Light Percipitation", "Heavy Percipitation")) +
  labs(title = "Bike Rentals by Weather Situation", x = "Weather Situation", y = "Total Bike Rentals") +
  theme_minimal()


season_vs_cnt = ggplot(bike_data, aes(x = factor(season), y = cnt)) +
  geom_boxplot(fill = "lightgreen", color = "black", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Bike Rentals by Season", x = "Season", y = "Total Bike Rentals")

weekday_rental = ggplot(bike_data, aes(x = factor(weekday), y = cnt, fill = factor(weekday))) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  scale_fill_viridis_d() +
  scale_x_discrete(labels=c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")) +
  labs(title = "Bike Rentals by Weekday", x = "Weekday", y = "Total Bike Rentals") +
  theme_minimal()

humidty_rental = ggplot(bike_data, aes(x = hum, y = cnt)) +
  geom_point(color = "purple", alpha = 0.5) +
  theme_minimal() +
  labs(title = "Humidity vs Bike Rentals", x = "Humidity", y = "Total Bike Rentals")

wind_rental = ggplot(bike_data, aes(x = windspeed, y = cnt)) +
  geom_point(color = "green", alpha = 0.5) +
  theme_minimal() +
  labs(title = "Windspeed vs Bike Rentals", x = "Wind Speed", y = "Total Bike Rentals")

options(repr.plot.width=20)
ggarrange(temp_vs_rentals, weather_vs_cnt, season_vs_cnt, weekday_rental, humidty_rental, wind_rental)

```

**Figure 1.** Distributions of dependent variables vs bike rental counts

```{r}
total_rentals
```

**Figure 2.** Distribution of bike rental counts

The data was split into training (75%) and testing (25%) sets, stratified by cnt (total bike counts). To ensure we had enough data representation in the test set, we computed the median, mean, and standard deviation for both data sets to make sure they were similar.

```{r best subset}
bike_split <- initial_split(bike_data, prop = 0.75, strata = cnt)
bike_train <- training(bike_split)
bike_test <- testing(bike_split)

bike_train_summary <- bike_train |> 
    summarize(median_cnt = median(cnt, na.rm = TRUE),
             mean_cnt = mean(cnt, na.rm = TRUE),
             standard_deviation_cnt = sd(cnt, na.rm = TRUE))

bike_test_summary <- bike_test |> 
    summarize(median_cnt = median(cnt, na.rm = TRUE),
             mean_cnt = mean(cnt, na.rm = TRUE),
             standard_deviation_cnt = sd(cnt, na.rm = TRUE))

bike_tt_summary <- bind_rows(bike_train_summary, bike_test_summary) |>
    mutate(partition = c("Train", "Test"),
           fraction = c(0.8, 0.2))|> 
    relocate(partition, fraction)
bike_tt_summary

```

**Table 1.** Summary statistics for response variable (cnt) for each data split.

To determine the most appropriate model, we used the best subset framework. Because weather is a categorical variable, we needed to check if the model with or without weather did better to determine our final model.

```{r}
best_models <- regsubsets(log(cnt)~ season + holiday + workingday + weathersit + temp + hum + windspeed, data = bike_train, nvmax = 11)

res.sum <- summary(best_models)

data.frame(
  R2 = which.max(res.sum$rsq),
  Adj.R2 = which.max(res.sum$adjr2)
)
```

**Table 2.** Model with largest R^2^ and adjusted R^2^

We created two linear regression models with and without weather respecively to assess their impact on bike demand. Because the model that included weather had a higher adjusted R^2^ , we decided to use that model as our final regression model.

```{r}
bike_model_with_weather = lm(log(cnt) ~ season + holiday + workingday + weathersit + temp + hum + windspeed, data = bike_train)
res_with <- summary(bike_model_with_weather)
bike_model_no_weather = lm(log(cnt) ~ season + holiday + workingday + temp + hum + windspeed, data = bike_train)
res_no <- summary(bike_model_no_weather)
data.frame(
  Adj.R2_with = res_with$adj.r.squared,
  Adj.R2_without = res_no$adj.r.squared
)

```

**Table 3.** Comparing model with and without weather

```{r}
final_bike_model = bike_model_with_weather
tidy(final_bike_model)
```

**Table 4.** Final model summary

To assess the model fit, we generated a residual plot. This plot indicates that even with our log transformation, the residuals are a bit heteroscedastic, and in future renditions of this project we plan to adopt a different, more appropriate model.

```{r test final model}
ggplot(bike_train,aes(x= fitted(final_bike_model),y = residuals(final_bike_model)))+
geom_point(alpha = 0.5)+
geom_hline(yintercept = 0,linetype = 'dashed',color = "red")+
labs(title = "Residual plot", x = "Fitted values", y = "Residuals")

```

**Figure 3.** Residual plot of final model

Finally, to evaluate prediction accuracy we calculated RMSE, which we found to be 1.29 uses approximately, suggesting the model prediction is good and our model is useful.

```{r}
predictions = predict(final_bike_model, newdata = bike_test)
RMSE = rmse(preds = predictions, actuals = log(bike_test$cnt))
data.frame(RMSE)
```

**Table 5.** RMSE

### Discussion

We found that the ideal model for our data includes season, holiday status, wether it is a working day, the temperature, the humidity, and the wind speed. We found that our model became stronger with the inclusion of weather-related variables. Though none of these findins are individually surprising, we were surprised that all of the variables had an impact on bike demand prediction and wonder if more research can be done into what other variables may also be used in this model. These findings suggest that these variables can significantly influence bike demand, information that can be used to help increase total users.

Future Questions:

Could a non-linear model be more accurate in terms of prediction?

How do long-term weather trends affect the seasonal bike usage?

What other outside variables are impactful in the prediction of bike-share usage?

### **Citations**

Teschke, K. (n.d.). *Bike share*. Cycling in Cities. <https://cyclingincities.spph.ubc.ca/motivating-cycling/bikeshare-systems/>

R Core Team. 2019. R: *A Language and Environment for Statistical Computing.* Vienna, Austria: R Foundation for Statistical Computing. [https://www.R-project.org/](https://www.r-project.org/).

Wickham H (2016). *ggplot2: Elegant Graphics for Data Analysis*. Springer-Verlag New York. ISBN 978-3-319-24277-4, [https://ggplot2.tidyverse.org](https://ggplot2.tidyverse.org/).

Fanaee-T, H. (2013). *Bike Sharing [Dataset]*. UCI Machine Learning Repository. <https://doi.org/10.24432/C5W894>.
